
defaults:
  - model@model: ???
  - data@_global_: features
  - _self_

# mlflow
path_to_mlflow: mlruns
experiment_name: ???

# datasets
vs_type: ???
dataset_name: SM_v4 # to log to mlflow for bookkeeping
datasets: 
  train:
    SM_v4: # will take all files from "train" subfolder of this dataset
      path_to_dataset: ./datasets
      tau_types: ['tau', '${vs_type}']
  val:
    SM_v4: # will take all files from "val" subfolder of this dataset
      path_to_dataset: ./datasets
      tau_types: ['tau', '${vs_type}']  

# TF dataset formation
tf_dataset_cfg:
  smart_batching_step: 10
  sequence_length_dist_start: 0
  sequence_length_dist_end: 300 
  shuffle_buffer_size: 40000 # null to not shuffle
  shuffle_smart_buffer_size: 1000
  cache: null # null to not cache the training dataset
  train_batch_size: 128
  val_batch_size: 128
  classes: ["tau", "${vs_type}"] # will pick only those labels (in this order)

# training
learning_rate: 0.0001
n_epochs: 1

# gpu
gpu_id: 0
memory_limit: 8 # in Gb
